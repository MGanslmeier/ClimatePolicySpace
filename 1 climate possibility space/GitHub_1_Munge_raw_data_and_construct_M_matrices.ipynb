{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa00087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import scipy.stats as sst\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 400\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047c7ef",
   "metadata": {},
   "source": [
    "### Key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d17d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_split(df, column, sep=',', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def create_N_and_M_matrices(climate_policy_dataframe):\n",
    "    \"\"\"\n",
    "    Creates N and M matrices from raw climte policy database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    N and M matrices\n",
    "    \"\"\"    \n",
    "    \n",
    "    # First, create N matrix and dataframe that sums up all the policies countries have announced in different policy instrument categories\n",
    "    \n",
    "    #N dataframe\n",
    "    N_df = pd.pivot_table(climate_policy_dataframe,values = 'ones',index = 'Country', columns = 'Type of policy instrument', aggfunc = np.sum)\n",
    "    #N matrix\n",
    "    N = np.nan_to_num(N_df)\n",
    "\n",
    "    # Second, create M matrices and dataframes based on two alternative approaches:\n",
    "    # M_Nci takes a binary value 1 if country has announced a policy (ever) and zero otherwise\n",
    "    M_Nci = np.where(N >= 1,1,0)\n",
    "    M_Nci_df = pd.DataFrame(data = M_Nci, index = N_df.index, columns = N_df.columns)\n",
    "\n",
    "    #M_RPP takes a binary value 1 if the country's Relative Policy Prevalence is > 1\n",
    "    RPP_bipartite = np.zeros(M_Nci.shape)\n",
    "    M_RPP = np.zeros(M_Nci.shape)\n",
    "    num_countries = len(N[:,0])\n",
    "    num_policies = len(N[0,:])\n",
    "    total_policy_prevalence = N.sum()\n",
    "    for p in range(num_policies):\n",
    "        global_policy_prevalance = N[:,p].sum()\n",
    "        for c in range(num_countries):\n",
    "            country_policy_prevalence = N[c,p]\n",
    "            country_total_prevalence = N[c,:].sum()\n",
    "\n",
    "            numerator = country_policy_prevalence/float(country_total_prevalence)\n",
    "            denominator = global_policy_prevalance/float(total_policy_prevalence)\n",
    "            RPP_bipartite[c,p]=np.nan_to_num(numerator/float(denominator))\n",
    "            if RPP_bipartite[c,p]>1:\n",
    "                M_RPP[c,p]=1\n",
    "\n",
    "    M_RPP_df = pd.DataFrame(M_RPP,index = N_df.index,columns = N_df.columns)    \n",
    "    \n",
    "    return N, N_df, M_Nci, M_Nci_df,M_RPP, M_RPP_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d658d1",
   "metadata": {},
   "source": [
    "### Read and munge raw data to create climate policy dataframe used in this paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a8ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw climate policy space (CPS) database\n",
    "df = pd.read_csv('github_raw/climate_policy_database.csv', encoding = \"latin1\")\n",
    "\n",
    "# Only consider policies at the country level\n",
    "df_use = df[df['Jurisdiction']=='Country']\n",
    "df_all_policies = df_use.copy()\n",
    "\n",
    "# Read in WB country income and region group labels\n",
    "WB_country_data = pd.read_csv('github_raw/WB_country_labels.csv', encoding = 'latin1')\n",
    "\n",
    "# Merge with CPS data\n",
    "df_WB = pd.merge(df_all_policies,WB_country_data, left_on = 'Country ISO', right_on = \"Code\", how = 'left')\n",
    "\n",
    "#s Slit data by policy instrument type\n",
    "df_instruments = tidy_split(df_use,'Type of policy instrument',sep =',')\n",
    "df_instruments['Type of policy instrument'] = df_instruments['Type of policy instrument'].str.strip()\n",
    "df_instruments = pd.merge(df_instruments,WB_country_data, left_on = 'Country ISO', right_on = \"Code\", how = 'left')\n",
    "df_instruments['ones']=np.ones(len(df_instruments))\n",
    "trend_instrument = df_instruments.groupby(['Type of policy instrument','Date of decision']).agg({'ones':'count'}).reset_index()\n",
    "\n",
    "# Drop all categories and sub categories and only use the most detailed level policy instruments\n",
    "not_include = ['Energy efficiency target','Renewable energy target','Target','GHG reduction target', 'Direct investment','Fiscal or financial incentives','Market-based instruments','Codes and standards','Regulatory Instruments','Economic instruments','Information and education','Performance label','Policy support','Research & Development and Deployment (RD&D)','Research programme','Volunatary approaches','Climate strategy','Target']\n",
    "\n",
    "### output climate policy dataframe\n",
    "CPD = df_instruments[~df_instruments['Type of policy instrument'].isin(not_include)]\n",
    "CPD.to_csv('github_intermediate/country_policy_dataframe.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1050611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and output N and M matrices\n",
    "\n",
    "N, N_df, M_Nci, M_Nci_df,M_RPP, M_RPP_df = create_N_and_M_matrices(CPD)\n",
    "\n",
    "# Save N matrix and dataframe \n",
    "np.savetxt('github_intermediate/N_matrix.csv',N,delimiter = ',')\n",
    "N_df.to_csv('github_intermediate/N_df.csv')\n",
    "\n",
    "# Save M matrix based on Nci approach\n",
    "np.savetxt('github_intermediate/M_Nci_matrix.csv',M_Nci, delimiter = ',')\n",
    "M_Nci_df.to_csv('github_intermediate/M_Nci_df.csv')\n",
    "\n",
    "# Save M matrix based on RPP approach\n",
    "np.savetxt('github_intermediate/M_RPP_matrix.csv', M_RPP, delimiter = ',')\n",
    "M_RPP_df.to_csv('github_intermediate/M_RPP_df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dab4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
